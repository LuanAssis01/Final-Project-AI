# Paths
paths:
  data_dir: './data'
  train_images: './data/train_images'
  train_masks: './data/train_masks'
  test_images: './data/test_images'
  supplemental_images: './data/supplemental_images'
  supplemental_masks: './data/supplemental_masks'
  checkpoints_dir: './checkpoints'
  results_dir: './results'
  submission_file: './data/sample_submission.csv'

# Dataset
dataset:
  image_size: 512  # Redimensionar imagens para 512x512
  train_split: 0.8  # 80% treino, 20% validação
  batch_size: 8  # Ajustar conforme VRAM disponível (6GB)
  num_workers: 4
  pin_memory: true
  seed: 42

augmentation:
  train:
    horizontal_flip: 0.5
    vertical_flip: 0.5
    rotation: 15
    brightness: 0.2
    contrast: 0.2
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
  
  val:
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

# Modelos a serem comparados
models:
  simple_cnn:
    name: 'SimpleCNN'
    input_channels: 3
    num_classes: 2  # authentic vs forged
    base_filters: 32
    
  resnet_transfer:
    name: 'ResNet50Transfer'
    backbone: 'resnet50'
    pretrained: true
    num_classes: 2
    freeze_backbone: false  # Fine-tuning
    
  unet_segmentation:
    name: 'UNet'
    encoder_name: 'resnet34'  # Encoder pré-treinado
    encoder_weights: 'imagenet'
    in_channels: 3
    classes: 1  # Máscara binária (forged region)

# Training
training:
  epochs: 50
  patience: 10  
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: 'adam'  # adam, sgd, adamw
  scheduler: 'reduce_on_plateau'  # reduce_on_plateau, cosine_annealing
  
  # Loss functions
  loss:
    simple_cnn: 'cross_entropy'
    resnet_transfer: 'cross_entropy'
    unet_segmentation: 'dice_bce'  # Combinação Dice + BCE para segmentação
  
  # Class weights (para dataset desbalanceado)
  use_class_weights: true
  
  # Mixed precision training (economizar VRAM)
  mixed_precision: true
  
  # Gradient clipping
  clip_grad_norm: 1.0

# Validation
validation:
  eval_frequency: 1  # Avaliar a cada epoch
  save_best_only: true
  metric_for_best: 'f1_score'  # f1_score, accuracy, iou

# Metrics
metrics:
  classification:  # Para SimpleCNN e ResNet
    - 'accuracy'
    - 'precision'
    - 'recall'
    - 'f1_score'
    - 'auc_roc'
    - 'confusion_matrix'
  
  segmentation:  # Para UNet
    - 'pixel_accuracy'
    - 'iou'  # Intersection over Union
    - 'dice_coefficient'
    - 'precision'
    - 'recall'

# Inference
inference:
  batch_size: 16
  tta: false  # Test Time Augmentation
  threshold: 0.5  # Para classificação binária

# Logging
logging:
  log_dir: './logs'
  tensorboard: true
  save_frequency: 5  # Salvar checkpoint a cada N epochs
  verbose: true

# Hardware
hardware:
  device: 'cuda'  # cuda ou cpu
  gpu_id: 0
  deterministic: true
  benchmark: false  # Otimização para inputs de tamanho fixo
